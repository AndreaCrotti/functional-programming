FUNCTIONAL PROGRAMMING

* Exam study
** Questions
   - why folie 9.c is not computable?
   - ex 6.2.b why they aren't binary operators?
   - check correlation between computability and monotonicity
   - ex 6.4.c why is the function monotonic?
   - definition of flat domain (from ex 7.2.3)
   - check passage in 7.2.b
   - what's the /otherwise/ for in ex 7.3.b
   - why the higher order function f_inf does not diverge in 7.3?
   - what means applying n times the function on $\bot$ (7.3)?
   - how can I count simply the number of elements in a tree only given the number of $\bot$ (8.1)?
   - Why defining recursively the elements in 8.1.d?
   - see better how to do exercise 8.2
   - why in folie 17(b) it says "up to rule 10" 

** Tricky parts
*** Sheet 1
    - Always remember to write also the base case in recursive definitions
      
*** Sheet2
    - 1.a
      type([] : []) = \[[a]\] because the second [] could be a list of lists
    - 1.d
      ([], [], :) a tuple can contain anything is not type sensitive like lists
    - 1.i
      We need to unify first the second part and then the first part, finally we get the result.
    - 1.j
      $\\x y \rightarrow [z, y] where z = \\x \rightarrow x*x$
      Not a valid haskell expression since they *can't* contain *where*.

*** Sheet3
    - 2
      see mapTree and foldTree implementation for good examples of recursion
      
*** Sheet4
    - 3
      Remember how to write corecursive definitions of functions, for example
#+begin_src haskell
f :: [[Int]] -> [[Int]]
f x = [map (^2) y | y <- x]

g :: [[Int]]
g = [2,3] : f g
#+end_src

*** Sheet5
    - 1.c
      Even better, "print $ replicate n '*'$ and then use intersperse or lists

    - 2
      Prove monad laws:
      Take every possible value of p and apply the rules given in the monad to prove correct.
      When you find the equality you've proved the law.
      For more complicated cases make sure that x does not occur in q, for example:

#+begin_src haskell
(\x -> q) v >>= \y -> r --becomes..
q[x/v] >>= \y -> r -- where now x does not occur in r
#+end_src

    - 3.c
      see [[file:official/solution5.hs][official solution]] for a better way to do it
      Strings should only be in *show*, not fixed in any other place.

*** Sheet6
    - 1.
      Element at the same level of definedness are not comparable, arrows go from the most defined to the least defined.
      To compute the number of elements of $f \\x \rightarrow y$ we need to give *all* the possible couple of the relations.
      For example set $B_\bot \rightarrow B^3_\bot$ has $|B_\bot^3|^{|B_\bot|}$ elements.
    
    - 2.
      Find monotonic extensions simply mean to define the function in the case of $\bot$, in such a way that it's still monotonic.
      A function is strict if at least one undefined symbol in input always give undefined in output.

    - 3.
      $strict \rightarrow monotonic$ but not viceversa
      To prove strictness is enough to show that whenever we have a $\bot$ in input we produce a $\bot$ in output. \\
      1 <= 1 always holds (for example).

    - 4.
      To show that a chain has a LUB
      + find it
      + prove that is an Upper Bound
      + prove that is <= of all the possible Upper Bounds
      
      A /reflexive partial order/ is a /complete partial order/ if
      - /D/ has the smallest element $\bot_D = \emptyset$
      - every chain /S/ over /D/ has a lub $\bigsqcup S \in D$

      A function is continuous whenever: \\
      $f(\bigsqcup M') = \bigsqcup f(M')$

*** Sheet7
    - 1.
      A simple symbol manipulation, make sure you write formally correctly.
      $(g \circ f)(\bigsqcup S) ... \rightarrow \bigsqcup(g \circ f)(S)$
    - 2.
      First prove monotonicity, then use that to prove also that is continuous.
      To prove monotonicity try every possible case and use premises when needed, for example
      + $x + \bot = \bot$
      + partial order defined on the initial function g1, g2 and so on

      Since we already have that it's monotonic, we know that if it's $\sqsubseteq$ it also must be equal.
      So we just need to show that monotonicity holds when applying to the /x/.

      Then again divide in the 3 possible cases of the /x/ and show the property for all of them.
    - 3.
      

*** Sheet8
    - 1.
      Make sure you also include the $\bot$ and $A \bot$ elements in the graph, they're also part of the domain.
      Always include all the possibilities given.
    

* Type inference algorithm /W/
  Given an haskell program we can then use the following process:
  $haskell \rightarrow simple haskell \rightarrow lambda calculus \rightarrow type inference$
  So every haskell program can by typed with the type inference algorithm.
  We have some initial type assumptions and predefined functions, then we get a type inference algorithm that makes substitutions until the new type is found.

** Algorithm
   /W(a,t)/ is either a pair (\theta, \tau) or the computation fails because of a failing unification problem.
   

* Innermost
  call by value

* Outermost
  call by name
** Pros
   Only evaluate subexpressions needed for overall result

** Cons
   Sometimes you have to evaluate more than once some of the expressions

   Haskell uses the so called *lazy evaluation*
   
   Basically outermost evaluation, but keeping memory of *different evaluations*, keeping tracks of duplicates and evaluates them all in parallel.
   
   An example where outermost is better could be
   
#+BEGIN_SRC haskell
   three :: Int -> Int
   three x = 3
   costly :: Int -> Int
   costly x = longcomputation
#+END_SRC

and here *three (costly x)* with innermost would take a very long time but the result is always 3.

We can define functions that work on infinite data structures.

* DECLARATIONS
** Conditional defining equations

#+BEGIN_SRC haskell
  -- you can use tuples here
  maxi :: (Int, Int) -> Int
  maxi (x, y)
  | x >= y = x
  | otherwise = y
#+END_SRC

** Currying

#+BEGIN_SRC haskell
  -- equivalent solution
  plus :: Int -> Int -> Int
  plus :: (Int, Int) -> Int
  plus :: Int -> (Int -> Int) -- takes int and returns another functions
#+END_SRC

  Application always associates *to the left*

  I can define a higher order function
  
#+BEGIN_SRC haskell
  suc :: Int -> Int
  suc = plus 1
#+END_SRC

*** Advantages of currying
    - Apply functions to only one argument

** Pattern matching

The order does matter, the first matching expression will be executed

#+BEGIN_SRC haskell
  und :: Bool -> Bool -> Bool
  und True y = y
  und False y = False
#+END_SRC

*** Pattern matching for different data structures
#+BEGIN_SRC haskell
   Bool -> True | False
   [a] -> [] | a : [a]

   len :: [a] -> Int
   len [] = 0
   len (x:xs) = 1 + len xs
#+END_SRC

#+resname:
: <interactive>:1:11: parse error on input `='

** Pattern declaration
  Assign a unique value to every variable in the pattern.
 
#+BEGIN_SRC haskell
  x1, y1 :: Int
  [x1, y1] = [1,2]
  -- every variable gets an unique value
#+END_SRC
  
** Operators Infix declarations
   $2 + 3 \rightarrow$ infix symbol
   $(+) \rightarrow$ prefix symbol
   
   Fixity can be shifted between prefix/infix.

** Association
   We normally associate to the right, but we can define ourselves where the associativity should go.
   *infixl* *infixr*
   *infix*, associates neither to left or right
   45 `divide` 5 `divide` 3 gives error in this case
   
   - *:* associates to the right, $3:4:[] \rightarrow 3:(4:[])$

   - function application associates to the left (square square 3)

** Priority
   We can define a number of priority in infix priority (between 0 and 9 (which is default)).
# check that this doesn't make latex crazy
   - infixl 9 %%
   - infixl 8 @@

* Expressions
  First haskell checks the type and IF is well typed than the expression is evaluated.

* Programming with lazy evaluation
  - In general we use leftmost evaluation
  - some pre-defined arithmetical operators require fully evaluated arguments
  - with pattern matching arguments are evaluated until one can decide which to pick

* Monads
  *return :: a -> IO a*
  Does nothing and incapsulates an object of type a.
  
  *(>>) :: IO a -> IO b -> IO b*
  chain something somewhere else.

  For example:
  *getChar >> return ()* takes a character and then ignores it.

  *(>>=) :: Io a -> (a -> IO b) *
  It gives you back another action.

  Getting input from the shell:

#+begin_src haskell
  gets :: Int -> IO String
  gets 0 = return []
  gets (n+1) = getChar >>= \x -> gets n
  -- which can be written much better as
  
  gets = do
    x <- getChar
    xs <- gets
    return (x:xs)
#+end_src

    In general monads are used to separate computations from inside the monads.
  

** Implement a monadic evaluator for terms

#+BEGIN_SRC haskell 
  data Term = Con Float | Div Term Term
  data Value a = Result a
  
  instance Show a => Show (Value a) where
      show (Result x) = "Result: " ++ show x
      
  -- now we instantiate the monad class
  instance Monad Value where
      return = Result
      (Result x) >>= x
      
  -- program eval in such a way using return/bind as much as possible
  eval1 :: Term -> Value Float
  eval1 (Con x) = return x
  eval1 (Div t u) = do
           x <- eval1 t
           y <- eval1 u
           return (Div x y)
  
  eval2 :: Term -> Maybe Float
  eval2 (Con x) = return x
  eval2 (Div t m) = do
    x <- eval2 t
    y <- eval2 u
    if y == 0 then Nothing
    else return (x / y)
#+END_SRC


   

* Theory
** Monotonic function
   
   
** Continuos function
   If $f : D1 -> D2$
   $\bigsqcup f(s) = f(\bigsqcup s)$

** Fix point theorem

* Simple haskell
** Some restrictions
   1. Only one declaration /var = exp/
   2. No predefined lists
   3. Only allow application of expressions in form /expr1 expr2/
   4. No case construct (no pattern matching)
   5. Lambda expressions only with variables instead of arbitrary patterns
   6. No /where/, only /let/
   A simple haskell program is a program without type synomyms and no type classes and no predefined lists.

   A simple haskell expression _exp_ is /transformed/ into _expr_ if we apply all the rules and we reach a fixed point.
   Application of the rules /terminates/ and the final result is *unique*.
   
** Free variable
   - free(_var_) = { _var_ }
   - free(_constr_) = free(_integer_)
   - free(_float_) = free(_char_) = \empty

** Predefined functions
   - bot :: a
   - isa_constr :: type -> Bool
   - argof_constr :: type -> (type_1... type_n)
   - isa_ntuple :: (a_1...a_n) -> Bool
   - sel_n,i :: (a_1...a_n) -> a_i

** 12 Rules to convert complex to simple haskell
*** Def 2.2.11
    Complex H-expression is transformed into exp by applying some rules as long as possible.

    This is the code that you want to transform to simple haskell
#+begin_src haskell
    append Nil z = z
    append (Cons x y) z = Cons x (append y z)
#+end_src
    After the iteration of all the rules it will be a simple haskell program.

**** 1. function to pattern declaration
     Functions defined with pattern matching will go into 1 case matching function.

**** 2. lambda with several patterns
     \pat_1... pat_n -> ... will go to \pat_1 -> (\pat_2 ...

**** 3. lambda patterns into case
     Using pattern matching inside lambda patterns is not possible, introduce a new variable and rewrite it with a case.

**** 4. /case/ into /match/
     a case becomes an innested conditional branch of /match/.
     case exp of {path1 -> exp1;
                 patn -> exp2}

**** 5. match of variables
     Matching can be translated to lambda

**** 6. match of joker pattern
      When first element is an expression you just take the expression1.
     match _ exp exp1 exp2
     _____________________
           exp1

**** 7. match of constructors
     Use instead *isa_constr* predefined function.
     match (constr pat1 patn) exp exp1 exp2
     _____________________________________
             if (isa constr exp)
	         then match (pat1, patn)
                 else exp2

**** 8. match of empty tuples
     Use *isa_0-tuple* instead

**** 9. match of non-empty tuple
     match (pat1, ... ,patn) exp exp1 exp2

**** 10. separation of declarations

**** 11. sequences of declarations into a single declaration

**** 12. declaration of several variables

* Implementing haskell (def 3.3.6)
  For a complex haskell program with the constructors Con, let \delta be the correspondign \delta-rule.
  Let P the sequence of pattern and function declarations, let _exp_ be a complex haskell-expression where all free variables are predefined or defined in P.
  _Evaluation_ of _exp_ in program P is done by WHNO-reduction with the above \delta-rules + \beta-reduction.

* Theorem 3.3.7 (Correctness of implementation)
  Our interpreter realizes undefinedness by non-termination (also if functions are not completely defined).
  f 1 would not terminate, our interpreter terminates if the value of our expression is not completely undefined.

* Confluent relation

* Lambda calculus
  See [[http://ellemose.dina.kvl.dk/~sestoft/lamreduce/lamframes.html][lambda term reducer online]] and also [[http://lci.sourceforge.net/doc/lcidoc010.html][lci]]

** \alpha reduction

** \beta reduction

** \delta reduction
   [[http://delta.reduction.word.sytes.org/][delta reduction]]
   This kind of reduction is not present in *pure* lambda calculus.
   A set \delta of rules of the form
   ct1...tn → r with c \in C,t1,...,tn, r \in \gamma is called a 
   delta-rule set if
   (1) t1, . . . , tn, r are closed lambda terms
   (2) all ti are in \beta-normal form
   (3) the ti do not contain any left-hand side of a rule from \delta
   (4) in \delta the r exist no two rules c t1...tn → randct1...tm → r′ with m >= n.
   
   

* Type inference algorithm (Milner 1978)
  For every type assumption A and every t \in \Lambda, W(A,t) is a pair (\theta, \tau) with a substitution \theta and a type \tau or the algorithm fails (because it's not unifiable).
  If W(A,t) succeeds, then we say that t is well-type under the type assumption A.

** Rules for W
   
